### **損失函數（Loss Function）基礎知識**：

**損失函數**是衡量預測結果與實際結果之間差異的函數。在機器學習和深度學習中，損失函數的目的是用來指導模型的訓練，最小化損失值，從而提升模型的預測精度。

#### **損失函數的基本概念**：

- **定義**：損失函數是一個數學函數，用來計算模型預測值與實際值之間的差距，並且作為模型優化的指標。
- **目的**：最小化損失函數，這樣可以讓模型的預測結果更接近實際結果，提升預測準確度。

#### **常見的損失函數**：

1. **均方誤差（Mean Squared Error, MSE）**：
    
    - 用於回歸問題，計算預測值與真實值之間差異的平方，然後取平均。
    ![[損失函數-均方誤差.png]]
2. **平均絕對誤差（Mean Absolute Error, MAE）**：
    
    - 也是用於回歸問題，計算預測值與真實值之間的絕對誤差的平均。
    - ![[損失函數-平均絕對誤差.png]]
3. **交叉熵損失（Cross-Entropy Loss）**：
    
    - 用於分類問題，衡量實際標籤與預測標籤的差異。
    ![[損失函數-交叉熵.png]]
4. **類別交叉熵（Categorical Cross-Entropy Loss）**：
    
    - 用於多分類問題，計算每個類別的預測概率與真實類別標籤之間的差異。
    - ![[損失函數-類別交叉熵.png]]
5. **Huber Loss**：
    
    - 結合了 MSE 和 MAE，對於較小的誤差使用 MSE，對於較大的誤差使用 MAE，從而減少對異常值的敏感性。
    - ![[損失函數-Huber Loss.png]]e Loss）**：
    
    - 用於度量學習（metric learning），其目的是使相似的樣本對靠近，不相似的樣本對遠離。
    - ![[損失函數-對比損失.png]]
6. **Kullback-Leibler Divergence（KL 散度）**：
    
    - 用於衡量兩個概率分布之間的差異。經常用於生成模型（如變分自編碼器）。
    - ![[損失函數-KL散度.png]]

#### **損失函數的作用與選擇**：

- 損失函數的選擇直接影響模型的訓練效果和最終預測性能。選擇合適的損失函數能夠加速收斂並提高模型精度。
- 回歸問題常用 MSE 或 MAE，分類問題常用交叉熵損失。不同的問題需求可能會選擇不同的損失函數。

#### **考點**：

1. **損失函數的定義與作用**：
    
    - 熟悉損失函數的基本概念、目的及其在機器學習中的角色。
    - 理解如何選擇合適的損失函數來解決不同類型的問題（回歸、分類等）。
2. **常見損失函數的數學形式與應用**：
    
    - 熟練掌握 MSE、MAE、交叉熵損失等常用損失函數的數學公式。
    - 知道每種損失函數的優缺點以及適用情況。
    - 了解如何計算和解釋損失函數的值。
3. **損失函數與模型訓練的關係**：
    
    - 損失函數如何影響模型訓練過程，及其對模型優化的影響。
    - 熟悉常見損失函數如何被最小化（如通過梯度下降法）。
4. **損失函數的選擇**：
    
    - 如何根據問題的特性選擇合適的損失函數（如選擇 MSE 還是 MAE，選擇交叉熵還是其他）。
5. **擴展的損失函數**：
    
    - 熟悉對比損失、KL 散度等擴展損失函數的應用領域及其公式。

### **總結**：

損失函數是機器學習和深度學習中的核心組件，選擇正確的損失函數對模型的性能至關重要。了解每個損失函數的數學原理、適用場景以及如何在訓練中最小化損失，是理解模型優化過程的關鍵。