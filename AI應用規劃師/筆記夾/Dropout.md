### Dropout 的基礎知識

**Dropout** 是一種用於防止神經網絡過擬合（overfitting）的方法，通常在深度學習中使用。它通過隨機“丟棄”神經元來打破神經元之間的依賴關係，強迫網絡學會更為健壯的特徵，從而提高模型的泛化能力。

#### 1. **Dropout 的基本概念**

- 在每次訓練的過程中，隨機地將神經網絡中的部分神經元及其連接設置為零，即“丟棄”這些神經元。這樣就能讓每次訓練時使用的神經元子集不同，從而避免模型過度依賴某些特徵或神經元。
- Dropout 主要應用於隱藏層。

#### 2. **Dropout 的實現**

- 每次訓練時，對於每個神經元，它有一個機會被“丟棄”，這個機率稱為**丟棄率（dropout rate）**，一般用 ppp 表示。
- 例如，若丟棄率 p=0.5p = 0.5p=0.5，則每個神經元有 50% 的機會在訓練時被丟棄。

#### 3. **Dropout 的公式**

對於每個神經元 iii（包括其輸出）來說，它在一次訓練中被“丟棄”的機率為 ppp，即：

![[Dropout.png]]

#### 4. **Dropout 的工作原理**

- 在訓練階段，對於每一層的神經元，都以概率 ppp 丟棄一些神經元。
- 在測試階段，所有神經元都會被保留，但是每個神經元的輸出會乘以 (1−p)(1 - p)(1−p) 的縮放因子，這樣做是為了彌補訓練時丟棄神經元的效果，保證測試時神經元的輸出不會過大。

#### 5. **Dropout 的優勢**

- **減少過擬合**：通過隨機丟棄神經元，網絡無法依賴某一部分神經元來做決策，從而強化了模型的泛化能力，減少了過擬合的風險。
- **改善模型的穩定性**：每次訓練中，網絡的結構和參數有所不同，這樣使得網絡能夠學到更加穩定的特徵。

#### 6. **Dropout 的缺點**

- **增加訓練時間**：由於每次訓練都要丟棄部分神經元，這可能會導致訓練過程變慢。
- **可能需要調整學習率**：使用 Dropout 後，可能需要調整學習率等超參數，以達到最佳的訓練效果。

#### 7. **Dropout 的常見應用**

- **神經網絡中的隱藏層**：Dropout 通常用於隱藏層，特別是深度網絡中的中間層。
- **卷積神經網絡（CNN）**：在 CNN 中，Dropout 通常應用於全連接層（FC layer）中，對卷積層的應用較少，因為卷積層本身已經具有較好的泛化能力。

#### 8. **Dropout 的考試重點**

- **Dropout 的基本概念**：理解 Dropout 是如何隨機丟棄神經元來減少過擬合的。
- **Dropout 的數學公式**：能夠寫出 Dropout 隨機丟棄神經元的公式，並了解如何在訓練和測試階段進行調整。
- **Dropout 的應用場景**：了解 Dropout 主要應用在哪些層（如隱藏層、全連接層）以及其在不同類型神經網絡中的作用。
- **Dropout 的優缺點**：能夠分析 Dropout 的好處（如防止過擬合、提高泛化能力）以及缺點（如訓練時間增加、可能需要調整學習率等）。

### Dropout 相關公式

1. **Dropout 的丟棄公式**：
    
    ![[Dropout 丟棄公式.png]]
2. **Dropout 層的使用**：
    
    - 在訓練階段隨機丟棄神經元，但在測試階段保留所有神經元，並且將每個神經元的輸出進行縮放調整。